# TanGo 项目配置文件
# 复制此文件为 .env 并填入实际的配置值

# ==================== 后端服务配置 ====================
# 后端服务地址和端口
BACKEND_HOST=0.0.0.0
BACKEND_PORT=8877

# ==================== 前端服务配置 ====================
# 前端开发服务器端口
FRONTEND_PORT=3000
# 前端API基础地址（生产环境需要配置，开发环境会自动使用后端地址）
VITE_API_BASE_URL=http://localhost:8877
# 后端服务地址（用于前端开发环境自动构建API地址）
VITE_BACKEND_HOST=localhost
VITE_BACKEND_PORT=8877
# 是否使用多Agent模式（true=多Agent模式，false=单Agent模式，默认false）
# 注意：此配置也可以通过前端Settings页面运行时切换（优先级更高）
VITE_USE_MULTI_AGENT=true

# ==================== Eino AI框架配置 ====================
# Eino服务基础URL（火山引擎Ark服务地址）
EINO_BASE_URL=http://www.xxx.com/openai-compatible/v1
# ==================== AI模型认证配置 ====================
# 火山引擎Ark服务的APP ID和Key（用于API认证）
# 注意：请将下面的占位符替换为你的真实值
TAL_MLOPS_APP_ID=your_app_id_here

TAL_MLOPS_APP_KEY=your_app_key_here
# ==================== AI模型配置 ====================
# 是否使用AI模型调用（true=使用AI模型，false=使用Mock数据，默认true）
USE_AI_MODEL=true
# 意图识别模型列表（逗号分隔）
INTENT_MODELS=gemini-3-pro-image,gpt-5-nano,doubao-seededit-3-0-i2i,doubao-seed-1.6vision,glm-4.6v,gpt-4o,gemini-2.5-flash-preview,gpt-5-pro,gpt-5.1
# 图片识别模型列表（逗号分隔）
IMAGE_RECOGNITION_MODELS=gemini-3-pro-image,gpt-5-nano,doubao-seededit-3-0-i2i,doubao-seed-1.6vision,glm-4.6v,gpt-4o,gemini-2.5-flash-preview,gpt-5-pro,gpt-5.1
# 文本生成模型列表（逗号分隔，用于卡片生成和流式输出）
TEXT_GENERATION_MODELS=gemini-3-pro-image,gpt-5-nano,doubao-seededit-3-0-i2i,doubao-seed-1.6vision,glm-4.6v,gpt-4o,gemini-2.5-flash-preview,gpt-5-pro,gpt-5.1


# ==================== GitHub 图片上传配置 ====================
# GitHub Personal Access Token（需要 repo 权限）
# 获取方式：https://github.com/settings/tokens
# 注意：请将下面的 xxxxx 替换为你的真实 token
GITHUB_TOKEN=ghp_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
# GitHub 仓库配置
GITHUB_OWNER=your_github_username
GITHUB_REPO=your_repo_name
GITHUB_BRANCH=main
GITHUB_PATH=images/
# 图片大小限制（字节，默认 10MB）
MAX_IMAGE_SIZE=10485760
